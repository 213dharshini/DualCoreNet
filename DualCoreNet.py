# -*- coding: utf-8 -*-
"""Copy of Miniproject.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1o_yoR1YKtAHz6CEuDmQ_Jg6xIZA86PT1
"""

from google.colab import drive
drive.mount('/content/drive')

import numpy as np # linear algebra
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

!unzip "/content/drive/MyDrive/Mini project/dataset/DDSM.zip"

df_dicom = pd.read_csv('/content/csv/dicom_info.csv')

cropped_images = df_dicom[df_dicom.SeriesDescription=='cropped images'].image_path

full_mammo = df_dicom[df_dicom.SeriesDescription=='full mammogram images'].image_path

roi_img = df_dicom[df_dicom.SeriesDescription=='ROI mask images'].image_path

imdir = '/content/jpeg'
# change directory path of images
cropped_images = cropped_images.replace('CBIS-DDSM/jpeg', imdir, regex=True)
full_mammo = full_mammo.replace('CBIS-DDSM/jpeg', imdir, regex=True)
roi_img = roi_img.replace('CBIS-DDSM/jpeg', imdir, regex=True)

# view new paths
print('Cropped Images paths:\n')
print(cropped_images.iloc[0])
print('Full mammo Images paths:\n')
print(full_mammo.iloc[0])
print('ROI Mask Images paths:\n')
print(roi_img.iloc[0])

import PIL
for file  in cropped_images[0:5]:
    cropped_images_show = PIL.Image.open(file)
    gray_img= cropped_images_show.convert("L")
    plt.imshow(gray_img, cmap='gray')

for file  in roi_img[0:5]:
    ROI_mask_images_show = PIL.Image.open(file)
    gray_img= ROI_mask_images_show.convert("L")
    plt.imshow(gray_img, cmap='gray')
    print(gray_img.size)

full_mammo_dict = dict()
cropped_images_dict = dict()
roi_img_dict = dict()

for dicom in full_mammo:
    key = dicom.split("/")[4]
    full_mammo_dict[key] = dicom
for dicom in cropped_images:
    key = dicom.split("/")[4]
    cropped_images_dict[key] = dicom
for dicom in roi_img:
    key = dicom.split("/")[4]
    roi_img[key] = dicom

next(iter((full_mammo_dict.items())))

dicom_data = pd.read_csv('/content/csv/dicom_info.csv')
dicom_cleaning_data = dicom_data.copy()
dicom_cleaning_data.head()

dicom_cleaning_data.drop(['PatientBirthDate','AccessionNumber','Columns','ContentDate','ContentTime','PatientSex','PatientBirthDate',
                                                'ReferringPhysicianName','Rows','SOPClassUID','SOPInstanceUID',
                                                'StudyDate','StudyID','StudyInstanceUID','StudyTime','InstanceNumber','SeriesInstanceUID','SeriesNumber'],axis =1, inplace=True)
dicom_cleaning_data.isna().sum()

dicom_cleaning_data['SeriesDescription'].fillna(method = 'bfill', axis = 0, inplace=True)
dicom_cleaning_data['Laterality'].fillna(method = 'bfill', axis = 0, inplace=True)
dicom_cleaning_data.isna().sum()

mass_train = pd.read_csv('/content/csv/mass_case_description_train_set.csv')
  mass_test = pd.read_csv('//content/csv/mass_case_description_test_set.csv')

  mass_train.head()

mass_train.pathology.unique()
mass_train.info()

mass_train = mass_train.rename(columns={'left or right breast': 'left_or_right_breast',
                                           'image view': 'image_view',
                                           'abnormality id': 'abnormality_id',
                                           'abnormality type': 'abnormality_type',
                                           'mass shape': 'mass_shape',
                                           'mass margins': 'mass_margins',
                                           'image file path': 'image_file_path',
                                           'cropped image file path': 'cropped_image_file_path',
                                           'ROI mask file path': 'ROI_mask_file_path'})

mass_train.head(5)

mass_train.isnull().sum()
# backwards fill method
mass_train['mass_shape'] = mass_train['mass_shape'].fillna(method='bfill')
mass_train['mass_margins'] = mass_train['mass_margins'].fillna(method='bfill')

#check null values
mass_train.isnull().sum()
# quantitative summary of features
mass_train.describe()
# view mass_test
mass_test.head()

print(f'Shape of mass_train: {mass_train.shape}')
print(f'Shape of mass_test: {mass_test.shape}')

mass_test.isnull().sum()
# check for column names in mass_test
print(mass_test.columns)
print('\n')
# rename columns
mass_test = mass_test.rename(columns={'left or right breast': 'left_or_right_breast',
                                           'image view': 'image_view',
                                           'abnormality id': 'abnormality_id',
                                           'abnormality type': 'abnormality_type',
                                           'mass shape': 'mass_shape',
                                           'mass margins': 'mass_margins',
                                           'image file path': 'image_file_path',
                                           'cropped image file path': 'cropped_image_file_path',
                                           'ROI mask file path': 'ROI_mask_file_path'})

# view renamed columns
mass_test.columns

mass_test['mass_margins'] = mass_test['mass_margins'].fillna(method='bfill')

#check null values
mass_test.isnull().sum()

mass_train = mass_train[mass_train['pathology'] != 'BENIGN_WITHOUT_CALLBACK']
mass_test = mass_test[mass_test['pathology'] != 'BENIGN_WITHOUT_CALLBACK']

masstrain=pd.DataFrame()
masstrain['pathology'] = mass_train['pathology']
masstrain['image'] = dicom_cleaning_data['image_path'][:1318]

masstest=pd.DataFrame()
masstest['pathology'] = mass_test['pathology']
masstest['image'] = dicom_cleaning_data['image_path'][:756:2]
masstest['image'] = masstest['image'].fillna(method='bfill')

masstrain['pathology'] = masstrain['pathology'].apply(lambda x: 0 if x == 'MALIGNANT' else 1)
masstest['pathology'] = masstest['pathology'].apply(lambda x: 0 if x == 'MALIGNANT' else 1)

proportion = masstrain['pathology'].value_counts(normalize=True)

# Print the result
print(proportion)

masstrain = masstrain.groupby('pathology', group_keys=False).apply(lambda x: x.sample(min(len(x), int(75* len(x) / len(masstrain)))))

# Reset the index
masstrain.reset_index(drop=True, inplace=True)



masstest = masstest.groupby('pathology', group_keys=False).apply(lambda x: x.sample(min(len(x), int(15* len(x) / len(masstest)))))

# Reset the index
masstest.reset_index(drop=True, inplace=True)

"""# **Data Visualization**"""

value = masstrain['pathology'].value_counts()
plt.figure(figsize=(8,6))

plt.pie(value, labels=value.index, autopct='%1.1f%%')
plt.title('Breast Cancer Mass Types', fontsize=14)
plt.show()

# examine breast assessment types
plt.figure(figsize=(8,6))
sns.countplot(mass_train, y='assessment', hue='pathology', palette='viridis')
plt.title('Breast Cancer Assessment\n\n 0: Undetermined || 1: Well Differentiated\n2: Moderately differentiated || 3: Poorly DIfferentiated\n4-5: Undifferentiated',
          fontsize=12)
plt.ylabel('Assessment Grade')
plt.xlabel('Count')
plt.show()

# examine cancer subtlety
plt.figure(figsize=(8,6))
sns.countplot(mass_train, x='subtlety', palette='viridis')
plt.title('Breast Cancer Mass Subtlety', fontsize=12)
plt.xlabel('Subtlety Grade')
plt.ylabel('Count')
plt.show()

plt.figure(figsize=(8,6))

sns.countplot(mass_train, x='mass_shape', hue='pathology')
plt.title('Mass Shape Distribution by Pathology', fontsize=14)
plt.xlabel('Mass Shape')
plt.xticks(rotation=30, ha='right')
plt.ylabel('Pathology Count')
plt.legend()
plt.show()

# breast density against pathology
plt.figure(figsize=(8,6))

sns.countplot(mass_train, x='breast_density', hue='pathology')
plt.title('Breast Density vs Pathology\n\n1: fatty || 2: Scattered Fibroglandular Density\n3: Heterogenously Dense || 4: Extremely Dense',
          fontsize=14)
plt.xlabel('Density Grades')
plt.ylabel('Count')
plt.legend()
plt.show()

"""###**Preprocessing**"""

import numpy as np
from PIL import Image
import cv2

# Load and preprocess the images for training and validation
def load_and_preprocess_images(image_paths):
    images = []
    for path in image_paths:
        # Load the image
        img = Image.open(path)
        img = img.resize((224, 224))  # Replace with your desired image dimensions
        img = np.array(img)  # Convert to a NumPy array
        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)
        img = img / 255.0  # Normalize the image (if needed)
        images.append(img)
    return np.array(images)



masstrain['image']=masstrain['image'].replace('CBIS-DDSM/jpeg', imdir, regex=True)
masstest['image']=masstest['image'].replace('CBIS-DDSM/jpeg', imdir, regex=True)

mass_train_images = load_and_preprocess_images(masstrain['image'])
mass_test_images = load_and_preprocess_images(masstest['image'])

# Ensure you have loaded labels as NumPy arrays as well
mass_train_labels_np = masstrain['pathology'].values
mass_test_labels_np = masstest['pathology'].values

"""### **DualCoreNet**

Conv2D-> Convolutional layer -> feature extraction, applying kernel (learnable filters) to scan for patterns and features like edges, textures, etc and then more complex ones in deeper layers.

MaxPooling2D -> Downsizing of layers by conv2D to reduce computational burden and focus on most essential information

Dense (Fully connected layer) -> Make high level decisions or classification. Combine the info from previous layers and generate output

Activation function ->
relu (rectified linear unit) -> introduce non linearity to do complex operations
softmax -> takes vector of numerical scores and converts them into probabilities. softmax (z)i = (e^zi)/(summation from j to K (e^zj))
"""

import tensorflow as tf
from tensorflow import keras

def create_lpl_model(input_shape, num_classes):
    lpl_model = keras.Sequential(name='LPL_Module')

    # Define the architecture for LPL here
    lpl_model.add(keras.layers.Input(shape=input_shape))
    lpl_model.add(keras.layers.Conv2D(64, kernel_size=3, activation='relu', padding='same'))
    lpl_model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))
    lpl_model.add(keras.layers.Conv2D(128, kernel_size=3, activation='relu', padding='same'))
    lpl_model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))
    lpl_model.add(keras.layers.Conv2D(128, kernel_size=3, activation='relu', padding='same'))
    lpl_model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))
    lpl_model.add(keras.layers.Conv2D(128, kernel_size=3, activation='relu', padding='same'))
    lpl_model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))
    lpl_model.add(keras.layers.Conv2D(128, kernel_size=3, activation='relu', padding='same'))
    lpl_model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))




    lpl_model.add(keras.layers.Flatten())
    lpl_model.add(keras.layers.Dense(256, activation='relu'))
    lpl_model.add(keras.layers.Dense(num_classes, activation='softmax'))

    return lpl_model

def create_cgl_model(input_shape, num_classes):
    cgl_model = keras.Sequential(name='CGL_Module')

    # Define the architecture for CGL here
    cgl_model.add(keras.layers.Input(shape=input_shape))
    cgl_model.add(keras.layers.Conv2D(64, kernel_size=3, activation='relu', padding='same'))
    cgl_model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))
    cgl_model.add(keras.layers.Conv2D(128, kernel_size=3, activation='relu', padding='same'))
    cgl_model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))
    cgl_model.add(keras.layers.Conv2D(128, kernel_size=3, activation='relu', padding='same'))
    cgl_model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))
    cgl_model.add(keras.layers.Conv2D(128, kernel_size=3, activation='relu', padding='same'))
    cgl_model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))
    cgl_model.add(keras.layers.Conv2D(128, kernel_size=3, activation='relu', padding='same'))
    cgl_model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))




    cgl_model.add(keras.layers.Flatten())
    cgl_model.add(keras.layers.Dense(256, activation='relu'))
    cgl_model.add(keras.layers.Dense(num_classes, activation='softmax'))

    return cgl_model

def create_fusion_model(input_shape, num_classes):
    # Create LPL and CGL models
    lpl_model = create_lpl_model(input_shape, num_classes)
    cgl_model = create_cgl_model(input_shape, num_classes)

    # Define the Fusion Model architecture
    fusion_input = tf.keras.layers.Input(shape=input_shape)
    lpl_features = lpl_model(fusion_input)
    cgl_features = cgl_model(fusion_input)

    # Combine the LPL and CGL features
    merged_features = tf.keras.layers.concatenate([lpl_features, cgl_features])

    # Add layers for the Fusion Model
    x = tf.keras.layers.Dense(256, activation='relu')(merged_features)
    fusion_output = tf.keras.layers.Dense(num_classes, activation='softmax')(x)

    model = tf.keras.Model(inputs=fusion_input, outputs=fusion_output, name='Fusion_Module')
    return model

input_shape = (224, 224, 3)
num_classes = 2

fusion_model = create_fusion_model(input_shape, num_classes)

# Compile the Fusion model with binary_crossentropy for binary classification
fusion_model.compile(
    optimizer='adam',
    loss='binary_crossentropy',
    metrics=['accuracy']
)

#adam -> Adaptive Moment Estimation
#Moment -> accelarate optimization by adding a fraction of previous update to current update
#RMSProp -> adjust learning rate individually based on magnitude of gradients

# Convert binary labels to one-hot encoded format (if not already)
from tensorflow.keras.utils import to_categorical

y_train_one_hot = to_categorical(masstrain['pathology'], num_classes=2)

history = fusion_model.fit(
    mass_train_images,
    y_train_one_hot,
    epochs=10,
    steps_per_epoch = 2,
    validation_data=(mass_test_images, to_categorical(masstest['pathology'], num_classes=2))
)

import matplotlib.pyplot as plt

plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

# Plot the training and validation accuracy (if it's a classification problem)
plt.subplot(1, 2, 2)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Training and Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

plt.tight_layout()
plt.show()